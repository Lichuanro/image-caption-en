{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Caption  \n",
    "I'll use pretrained coco dataset to train this image caption model  \n",
    "the dataset is in [http://www.cs.toronto.edu/~vendrov/order/coco.zip](http://www.cs.toronto.edu/~vendrov/order/coco.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained vgg-19 image data   \n",
    "The data is in 4096 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = './data/coco/images/10crop'\n",
    "train_data = np.load( os.path.join(path, 'train.npy'))\n",
    "val_data = np.load( os.path.join(path, 'val.npy'))\n",
    "test_data = np.load( os.path.join(path, 'test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (113287, 4096)\n",
      "validation data shape: (5000, 4096)\n",
      "test data shape: (5000, 4096)\n"
     ]
    }
   ],
   "source": [
    "print('train data shape: {}'.format(train_data.shape))\n",
    "print('validation data shape: {}'.format(val_data.shape))\n",
    "print('test data shape: {}'.format(test_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_text(file_path):\n",
    "    content = []\n",
    "    max_length = 0\n",
    "    with open(file_path, 'rb') as f:\n",
    "        for line in f:\n",
    "            content.append(line.strip())\n",
    "            if len(line.strip().split()) > max_length:\n",
    "                max_length = len(line.strip().split())\n",
    "    return np.array(content), max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_path = './data/coco'\n",
    "train_cap, train_max_length = read_text(os.path.join(text_path, 'train.txt'))\n",
    "val_cap, val_max_length = read_text(os.path.join(text_path, 'val.txt'))\n",
    "test_cap, test_max_length = read_text(os.path.join(text_path, 'test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train caption shape: (566435,), max length: 49\n",
      "validation caption shape: (25000,), max length: 47\n",
      "test caption shape: (25000,), max length: 43\n"
     ]
    }
   ],
   "source": [
    "print('train caption shape: {0}, max length: {1}'.format(train_cap.shape, train_max_length))\n",
    "print('validation caption shape: {0}, max length: {1}'.format(val_cap.shape, val_max_length))\n",
    "print('test caption shape: {0}, max length: {1}'.format(test_cap.shape, test_max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'a woman wearing a net on her head cutting a cake',\n",
       "       b'a woman cutting a large white sheet cake',\n",
       "       b'a woman wearing a hair net cutting a large sheet cake',\n",
       "       b'there is a woman that is cutting a white cake',\n",
       "       b'a woman marking a cake with the back of a chefs knife',\n",
       "       b'a young boy standing in front of a computer keyboard',\n",
       "       b'a little boy wearing headphones and looking at a computer monitor',\n",
       "       b'he is listening intently to the computer at school',\n",
       "       b'a young boy stares up at the computer monitor',\n",
       "       b'a young kid with head phones on using a computer'],\n",
       "      dtype='|S246')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cap[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each image related to 5 captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_vocab_int(text):\n",
    "    text = text.lower()\n",
    "    vocab = sorted(set(text.split()))\n",
    "    vocab_counter = Counter(vocab)\n",
    "\n",
    "    vocab = ['<PAD>','<EOS>','<UNK>','<GO>'] + vocab\n",
    "    vocab_to_int = {word: index for index, word in enumerate(vocab)}\n",
    "    int_to_vocab = {index: word for word, index in vocab_to_int.items()}\n",
    "    return vocab_to_int, int_to_vocab, vocab_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the input should be a list of sentences \n",
    "# and the output is the corresponding int value with the same length as the max length of the sentence\n",
    "# the output of each starts with the <GO> and ends with <EOS>, with <PAD> to fill the empty places\n",
    "def get_cap_id(sentences, vocab_to_int, max_length):\n",
    "    output = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.decode('utf-8')\n",
    "        new_line = [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in sentence.split()]\n",
    "        new_line.insert(0, vocab_to_int['<GO>'])\n",
    "        new_line.append(vocab_to_int['<EOS>'])\n",
    "        output.append(new_line)\n",
    "    output = [sentence + [vocab_to_int['<PAD>']] * (max_length - len(sentence))\n",
    "                    for sentence in output]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all the text to generate the dictionary\n",
    "total_text = ''\n",
    "for sentence in train_cap:\n",
    "    total_text += sentence.decode('utf-8')\n",
    "for sentence in val_cap:\n",
    "    total_text += sentence.decode('utf-8')\n",
    "for sentence in test_cap:\n",
    "    total_text += sentence.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_to_int, int_to_vocab, vocab_counter = get_vocab_int(total_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = get_cap_id(train_cap[:5], vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 696, 90544, 89111, 696, 50817, 52237, 37367, 36987, 21913, 696, 13234, 1]\n"
     ]
    }
   ],
   "source": [
    "print(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<GO>', 'a', 'woman', 'wearing', 'a', 'net', 'on', 'her', 'head', 'cutting', 'a', 'cake', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "print([int_to_vocab[i] for i in test[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input_dim = 4096\n",
    "max_length = max(train_max_length, val_max_length, test_max_length)\n",
    "cap_input_dim = len(vocab_to_int)\n",
    "cap_embed_dim = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_input = Input(shape=(4096,), name='image_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### caption input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap_input = Input(shape=(max_length,), dtype='int32', name='cap_input')\n",
    "x = Embedding(output_dim=cap_embed_dim, input_dim=cap_input_dim, input_length=max_length)(cap_input)\n",
    "lstm_out = LSTM(32)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenate the image input and LSTM input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = keras.layers.concatenate([lstm_out, image_input])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
